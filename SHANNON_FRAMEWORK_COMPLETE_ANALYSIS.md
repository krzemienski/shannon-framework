# Shannon Framework - Complete Exhaustive Analysis

**Generated**: 2025-11-17
**Purpose**: Build intelligent-do skill and /shannon:do command
**Analysis Depth**: Line-by-line exhaustive

---

## Executive Summary

Shannon Framework is a sophisticated AI orchestration system that enables:
- **Parallel agent execution** via wave-based orchestration (3.5x speedup)
- **Quantitative complexity analysis** via 8-dimensional scoring (0.0-1.0 scale)
- **Context preservation** across sessions using Serena MCP
- **Quality gates** enforcing NO MOCKS testing philosophy
- **Real-time control** with HALT/RESUME/ROLLBACK capabilities

**Architecture**: Plugin-based system with 19 skills, 16 commands, Python orchestration backend, React dashboard, WebSocket server for real-time control.

---

## 1. Python Infrastructure Analysis

### 1.1 Hooks System (`/hooks/`)

#### post_tool_use.py (164 lines)
**Purpose**: Enforce NO MOCKS testing philosophy in real-time

**Key Components**:
```python
MOCK_PATTERNS = [
    (r'jest\.mock\(', 'jest.mock()'),
    (r'unittest\.mock', 'unittest.mock'),
    (r'@[Pp]atch\b', '@patch decorator'),
    # ... 11 total patterns
]
```

**Workflow**:
1. Hook fires after Write/Edit/MultiEdit
2. Checks if file is test file (path contains 'test/', '.test.', etc.)
3. Scans content for mock patterns
4. If mocks detected â†’ BLOCKS with clear guidance
5. Recommends functional test alternatives (Puppeteer, real DBs)

**Decision Output** (when mocks found):
```json
{
  "decision": "block",
  "reason": "ðŸš¨ Shannon NO MOCKS Violation Detected...",
}
```

**Testing Philosophy Enforcement**: Automatic, real-time, no bypass

---

#### precompact.py (389 lines)
**Purpose**: Prevent context loss during Claude Code auto-compaction

**Key Innovation**: Generates Serena checkpoint instructions BEFORE compaction occurs

**Core Algorithm**:
```python
class ShannonPreCompactHook:
    def execute(self, input_data):
        checkpoint_key = f"shannon_precompact_checkpoint_{timestamp}"
        instructions = self._generate_checkpoint_instructions()

        return {
            "hookSpecificOutput": {
                "additionalContext": checkpoint_instructions,
                "checkpointKey": checkpoint_key
            }
        }
```

**Checkpoint Structure** (comprehensive):
```python
{
    "checkpoint_type": "auto_precompact",
    "serena_memory_keys": ["all keys from list_memories()"],
    "active_wave_state": {
        "current_wave": wave_number,
        "wave_phase": "planning|execution|synthesis",
        "active_sub_agents": [agent_names]
    },
    "phase_state": {...},
    "project_context": {...},
    "todo_state": {...},
    "decisions_made": [...],
    "integration_status": {...},
    "next_steps": [...]
}
```

**Critical Features**:
- Runs automatically when Claude approaches token limit
- Generates complete state snapshot
- Updates "shannon_latest_checkpoint" pointer
- Verifies save with read-back test
- Logs to `~/.claude/shannon-logs/precompact/`

**Restoration**: On session resume, SessionStart hook (or manual `/shannon:restore`) loads checkpoint

---

#### stop.py (99 lines)
**Purpose**: Enforce validation gates before completion

**Checks**:
1. **Wave Validation Pending**: Blocks if `.serena/wave_validation_pending` exists
2. **Critical TODOs Incomplete**: Blocks if `.serena/critical_todos_incomplete` exists

**Block Message**:
```
âš ï¸  Shannon Wave Validation Required

Wave X requires user approval before proceeding

**Required Actions**:
1. Present wave synthesis to user
2. Request explicit approval
3. Create checkpoint
4. Mark validation complete
```

**Iron Law Enforcement**: Cannot bypass even under deadline pressure

---

#### user_prompt_submit.py (73 lines)
**Purpose**: Inject North Star goal into every user prompt

**Workflow**:
1. Reads `.serena/north_star.txt`
2. If exists, injects as context prefix:
   ```
   ðŸŽ¯ **North Star Goal**: {goal}
   **Context**: All work must align with this overarching goal.
   ---
   ```
3. Reads `.serena/active_wave_status.txt`
4. If exists, injects wave context

**Impact**: Transforms static goal â†’ active context in every interaction

---

### 1.2 Orchestration System (`/orchestration/`)

#### orchestrator.py (307 lines)
**Purpose**: Coordinate parallel wave execution with real-time control

**Core Classes**:

```python
class ExecutionState(Enum):
    IDLE = "idle"
    RUNNING = "running"
    HALTED = "halted"
    COMPLETED = "completed"
    FAILED = "failed"

class Wave:
    wave_id: str
    agent_id: str
    tasks: List[str]
    status: str  # pending, running, halted, completed
    started_at: Optional[float]
    completed_at: Optional[float]

class Orchestrator:
    state: ExecutionState
    halt_requested: bool
    waves: List[Wave]
    current_wave_index: int
    execution_history: List[Dict]
    state_manager: StateManager
    decision_engine: DecisionEngine
```

**Key Operations**:

**1. Execute Waves**:
```python
async def execute(self) -> Dict[str, Any]:
    self.state = ExecutionState.RUNNING

    while self.current_wave_index < len(self.waves):
        # Check halt every 10ms (sub-100ms response)
        if self.halt_requested:
            await self._perform_halt()
            break

        # Create snapshot before wave
        self.state_manager.create_snapshot(
            self.current_wave_index,
            self.execution_history,
            self.waves
        )

        # Execute wave
        await self._execute_wave(wave)

        # Record to history
        self.execution_history.append({...})

        self.current_wave_index += 1

    return self.get_status()
```

**2. HALT (Sub-100ms Response)**:
```python
def halt(self) -> Dict:
    self.halt_requested = True  # Checked every 10ms
    return {
        "halt_requested": True,
        "current_state": self.state.value,
        "current_wave_index": self.current_wave_index
    }
```

**3. RESUME**:
```python
async def resume(self) -> Dict:
    if self.state != ExecutionState.HALTED:
        raise ValueError("Cannot resume")

    self.halt_requested = False
    self.state = ExecutionState.RUNNING
    return await self.execute()  # Continue from current position
```

**4. ROLLBACK (N steps)**:
```python
def rollback(self, n_steps: int) -> Dict:
    rollback_state = self.state_manager.get_rollback_state(n_steps)

    # Restore wave index, history, wave states
    self.current_wave_index = rollback_state["wave_index"]
    self.execution_history = rollback_state["execution_history"]

    # Reset waves to previous state
    for i, wave_state in enumerate(rollback_state["waves_state"]):
        self.waves[i].status = wave_state["status"]
        self.waves[i].started_at = wave_state.get("started_at")
        self.waves[i].completed_at = wave_state.get("completed_at")

    return {"rollback_steps": n_steps, ...}
```

**Integration**: Used by WebSocket server for dashboard control

---

#### state_manager.py (132 lines)
**Purpose**: Handle execution state snapshots for rollback

**Snapshot Storage**:
```python
class StateSnapshot:
    wave_index: int
    execution_history: List[Dict]  # Deep copy
    waves_state: List[Dict]  # Deep copy
    timestamp: float

class StateManager:
    snapshots: List[StateSnapshot]
    max_snapshots = 100  # Keep last 100
```

**Operations**:
- `create_snapshot()`: Save state before each wave
- `get_snapshot(steps_back)`: Retrieve N steps back
- `get_rollback_state()`: Get complete state for rollback
- `clear_snapshots()`: Reset on orchestrator reset

**Rollback Strategy**: Maintains complete execution history, allows time-travel debugging

---

#### decision_engine.py (188 lines)
**Purpose**: Human-in-the-loop decision making with auto-approval

**Core Concept**: Auto-approve high-confidence decisions (â‰¥0.95), otherwise request human approval

```python
@dataclass
class DecisionOption:
    id: str
    label: str
    description: str
    confidence: float  # 0.0-1.0
    pros: List[str]
    cons: List[str]
    metadata: Dict

@dataclass
class Decision:
    id: str
    question: str
    options: List[DecisionOption]
    status: str  # pending, approved, rejected
    selected_option_id: Optional[str]
    auto_approved: bool
    approved_by: str  # "auto" or user ID
```

**Request Decision**:
```python
async def request_decision(
    question: str,
    options: List[DecisionOption],
    context: Optional[Dict] = None
) -> Decision:
    highest_confidence = max(options, key=lambda opt: opt.confidence)

    if highest_confidence.confidence >= 0.95:
        # Auto-approve
        decision = Decision(
            status="approved",
            selected_option_id=highest_confidence.id,
            auto_approved=True,
            approved_by="auto"
        )
    else:
        # Requires human approval
        decision = Decision(
            status="pending",
            auto_approved=False
        )
        self.pending_decisions[decision_id] = decision

    return decision
```

**Integration**: WebSocket emits decision requests to dashboard, receives approvals

---

### 1.3 WebSocket Server (`/server/websocket.py`, 365 lines)

**Purpose**: Real-time communication between orchestrator and dashboard

**Architecture**:
```python
sio = socketio.AsyncServer(
    async_mode='asgi',
    cors_allowed_origins='*'
)

# Global instances
decision_engine = DecisionEngine()
orchestrator = None  # Set by server initialization
```

**Events Handled**:

**1. Decision Approval**:
```python
@sio.event
async def approve_decision(sid, data):
    decision_id = data['decision_id']
    selected_option_id = data['selected_option_id']

    decision = await decision_engine.approve_decision(
        decision_id,
        selected_option_id,
        approved_by=f"dashboard-{sid}"
    )

    await sio.emit('decision:approved', {
        'decision_id': decision.id,
        'selected_option': selected_option_id
    })

    await sio.emit('execution:resumed', {
        'reason': 'decision_approved'
    })
```

**2. HALT**:
```python
@sio.event
async def halt_execution(sid, data):
    result = orchestrator.halt()

    await sio.emit('execution:halted', {
        'success': True,
        'halt_response_time_ms': result.get('halt_response_time_ms')
    }, room=sid)

    await broadcast_status()
```

**3. RESUME**:
```python
@sio.event
async def resume_execution(sid, data):
    result = await orchestrator.resume()

    await sio.emit('execution:resumed', {
        'success': True,
        'result': result
    })
```

**4. ROLLBACK**:
```python
@sio.event
async def rollback_execution(sid, data):
    steps = data.get('steps', 1)
    result = orchestrator.rollback(steps)

    await sio.emit('execution:rolled_back', {
        'success': True,
        'steps': steps
    })
```

**Status Broadcasting**:
```python
async def broadcast_status():
    status = orchestrator.get_status()
    await sio.emit('execution:status_update', {'status': status})
```

---

### 1.4 Validation System (`/validate_shannon_v5.py`, 208 lines)

**Purpose**: Validate complete Shannon v5 system integrity

**Checks**:

```python
class ShannonValidator:
    def validate_all(self):
        self.validate_plugin_config()      # plugin.json, marketplace.json
        self.validate_commands()            # 16 commands/*.md files
        self.validate_skills()              # 19 skills/*/SKILL.md files
        self.validate_command_skill_mappings()  # @skill references
        self.validate_skill_dependencies()  # required-sub-skills
```

**Command Validation**:
```python
def validate_commands(self):
    for cmd_file in (self.root / "commands").glob("*.md"):
        content = cmd_file.read_text()

        # Check frontmatter
        if not content.startswith("---"):
            self.issues.append(f"{cmd_file.name}: Missing frontmatter")

        # Check name matches filename
        if f"name: {name}" not in frontmatter:
            self.issues.append(f"name doesn't match filename")

        # Check required fields
        if "description:" not in frontmatter:
            self.issues.append("Missing description")
```

**Skill Validation**:
```python
def validate_skills(self):
    for skill_dir in (self.root / "skills").iterdir():
        skill_file = skill_dir / "SKILL.md"

        # Check frontmatter structure
        # Check name matches directory
        # Check required fields (description)
```

**Dependency Validation**:
```python
def validate_skill_dependencies(self):
    # Extract required-sub-skills from YAML
    if dep and dep not in self.skills:
        self.issues.append(f"requires non-existent skill '{dep}'")
```

**Exit Code**: 0 if all pass, 1 if issues found

---

## 2. NO Serena MCP Usage in Python

**CRITICAL FINDING**: The Shannon Framework Python code does **NOT** directly invoke Serena MCP.

**Rationale**:
- Python code handles **infrastructure** (orchestration, websockets, hooks)
- **Skills** (written in Markdown) handle Serena MCP invocations
- Skills executed by Claude Code â†’ Claude invokes Serena MCP
- Python provides orchestration framework, not MCP client

**Example from wave-orchestration skill**:
```markdown
## Context Loading Protocol

Every agent prompt MUST include:

1. list_memories() - Discover available memories
2. read_memory("spec_analysis") - Load project context
3. read_memory("wave_1_complete") - Load previous wave
```

**Pattern**: Skills define WHAT to call, Claude Code executes calls, Python orchestrates execution

---

## 3. Skill Architecture Analysis

### 3.1 Skill Structure (Universal Pattern)

**YAML Frontmatter** (metadata):
```yaml
---
name: skill-name
description: |
  Multi-line description
  When to use

skill-type: QUANTITATIVE | PROTOCOL | ORCHESTRATION
shannon-version: ">=5.0.0"
complexity-triggers: [0.50-1.00]  # For quantitative skills

mcp-requirements:
  required:
    - name: serena
      purpose: Context preservation
  recommended:
    - name: sequential
      purpose: Deep thinking

required-sub-skills:
  - dependency-skill

optional-sub-skills:
  - enhancement-skill

allowed-tools: [Read, Write, Bash, Serena, Sequential]
---
```

**Markdown Content** (instructions):
1. **Purpose** - What the skill does
2. **When to Use** - Activation conditions
3. **Anti-Rationalization** - Common mistakes to avoid
4. **Iron Laws** - Non-negotiable rules
5. **Workflow** - Step-by-step execution
6. **Examples** - Concrete usage
7. **Success Criteria** - Validation checklist
8. **Common Pitfalls** - What goes wrong
9. **Integration** - How it connects to other skills

### 3.2 exec Skill (Autonomous Execution)

**Purpose**: Complete autonomous task execution with library discovery + 3-tier validation + atomic commits

**6 Phases**:

```
Phase 1: Context Preparation (30-60s)
â†’ /shannon:prime for session setup

Phase 2: Library Discovery (5-30s)
â†’ shannon discover-libs "[feature]" --json
â†’ Searches npm, PyPI, CocoaPods, Maven, crates.io
â†’ Caches in Serena (7-day TTL)

Phase 3: Task Analysis (Optional, 10-30s)
â†’ /shannon:analyze for complexity
â†’ Skip for simple, include for complex

Phase 4: Execution Planning (5-15s)
â†’ Simple (<0.30): Single-step plan
â†’ Complex (â‰¥0.30): Sequential MCP multi-step plan

Phase 5: Execution Loop (Per Step)
  5a. Execute via /shannon:wave with library context
  5b. Parse wave results (files changed)
  5c. Validate Changes (3-tier):
      Tier 1: Build + TypeCheck + Lint (10s)
      Tier 2: Tests (1-5min)
      Tier 3: Functional (2-10min)
  5d. Decision:
      IF all pass â†’ shannon git-commit
      ELSE â†’ shannon git-rollback, research, retry (max 3)

Phase 6: Execution Report
â†’ Summary: commits, branch, duration, libraries
â†’ Save to Serena: exec_result_{timestamp}
```

**Key Innovation**: Combines Shannon wave orchestration + Shannon CLI validation/git

**Library Discovery Integration**:
```bash
shannon discover-libs "authentication" --category auth --json
# Returns:
{
  "libraries": [
    {
      "name": "next-auth",
      "score": 95.0,
      "why_recommended": "15k+ stars, maintained 4 days ago",
      "install_command": "npm install next-auth"
    }
  ]
}
```

**3-Tier Validation** (enforced):
```bash
# Tier 1: Static
shannon validate --tier 1 --json  # Build, type check, lint

# Tier 2: Tests
shannon validate --tier 2 --json  # Unit/integration tests

# Tier 3: Functional
shannon validate --tier 3 --json  # Real system behavior
```

**Atomic Commits**:
```bash
shannon git-commit \
  --step "Add authentication" \
  --files "package.json,src/auth/login.tsx" \
  --validation-json '{"tier1_passed": true, ...}'
```

**Integration**: `exec` invokes `wave-orchestration` for code generation, Shannon CLI for validation

---

### 3.3 wave-orchestration Skill (Parallel Execution)

**Purpose**: Achieve 3.5x speedup through true parallel agent execution

**Core Algorithm** (Critical Path Method):

```python
# Step 1: Build dependency graph
dependency_graph = {
    phase_id: {
        "depends_on": [prerequisite_ids],
        "blocks": [dependent_ids]
    }
}

# Step 2: Generate wave structure
waves = []
remaining_phases = phases.copy()
completed_phases = set()

while remaining_phases:
    # Find phases with all deps satisfied
    ready_phases = [p for p in remaining_phases
                   if all(dep in completed_phases for dep in p.dependencies)]

    # Create wave
    waves.append({
        "wave_number": len(waves) + 1,
        "phases": ready_phases,
        "parallel": len(ready_phases) > 1,
        "estimated_time": max([p.estimated_time for p in ready_phases])
    })

    completed_phases.update(ready_phases)
    remaining_phases.remove_all(ready_phases)

# Step 3: Agent allocation (complexity-based)
for wave in waves:
    wave["agents_allocated"] = allocate_agents(complexity_score, wave)
```

**Agent Allocation Bands**:
```
Complexity 0.00-0.30 (Simple): 1-2 agents
Complexity 0.30-0.50 (Moderate): 2-3 agents
Complexity 0.50-0.70 (Complex): 3-7 agents
Complexity 0.70-0.85 (High): 8-15 agents
Complexity 0.85-1.00 (Critical): 15-25 agents
```

**True Parallelism** (CRITICAL):
```xml
<!-- CORRECT: All agents in ONE message -->
<function_calls>
  <invoke name="Task"><parameter name="prompt">Agent 1</parameter></invoke>
  <invoke name="Task"><parameter name="prompt">Agent 2</parameter></invoke>
  <invoke name="Task"><parameter name="prompt">Agent 3</parameter></invoke>
</function_calls>

Result: All 3 execute SIMULTANEOUSLY
Time: max(12, 12, 12) = 12 minutes

<!-- INCORRECT: Multiple messages (sequential) -->
Message 1: Agent 1 â†’ wait
Message 2: Agent 2 â†’ wait
Message 3: Agent 3

Result: SEQUENTIAL execution
Time: 12 + 12 + 12 = 36 minutes (NO SPEEDUP)
```

**Context Loading Protocol** (mandatory for every agent):
```markdown
## MANDATORY CONTEXT LOADING PROTOCOL

1. list_memories()
2. read_memory("spec_analysis")
3. read_memory("phase_plan_detailed")
4. read_memory("wave_1_complete") if exists
5. read_memory("wave_2_complete") if exists
...
7. read_memory("wave_[N-1]_complete")

Your task: [specific instructions]
```

**Wave Synthesis** (after EVERY wave):
```python
# Step 1: Collect agent results
results = [read_memory(f"wave_{N}_{agent}_results") for agent in wave_agents]

# Step 2: Aggregate deliverables
deliverables = {
    "files_created": merge_all(results.files),
    "components_built": list_all(results.components),
    "decisions_made": compile(results.decisions)
}

# Step 3: Cross-validate
quality_checks = [
    "Conflicting implementations?",
    "Missing integrations?",
    "Duplicate work?",
    "NO MOCKS compliance?"
]

# Step 4: Save synthesis
write_memory(f"wave_{N}_complete", {
    wave_number: N,
    agents_deployed: count,
    deliverables: {...},
    next_wave_context: {...}
})

# Step 5: Present to user
# Step 6: Wait for explicit approval
```

**Iron Laws** (non-negotiable):
1. Synthesis checkpoint after EVERY wave (even under deadline)
2. Dependency analysis MANDATORY (no skipping)
3. Complexity-based agent allocation (user estimates don't override)
4. Context loading for EVERY agent
5. True parallelism (all agents in one message)

---

### 3.4 spec-analysis Skill (8D Complexity Scoring)

**Purpose**: Transform specs â†’ quantitative project intelligence

**8 Dimensions** (weighted):

```python
total_score = (
    0.20 Ã— structural +    # Files, services, modules
    0.15 Ã— cognitive +     # Analysis, design depth
    0.15 Ã— coordination +  # Teams, integration
    0.10 Ã— temporal +      # Deadlines, urgency
    0.15 Ã— technical +     # Advanced tech, algorithms
    0.10 Ã— scale +         # Users, data volume
    0.10 Ã— uncertainty +   # TBDs, ambiguities
    0.05 Ã— dependencies    # Blockers, prerequisites
)
```

**Example Calculation** (from skill):
```
Structural: 0.55 (multiple services)
Cognitive: 0.65 (complex design)
Coordination: 0.75 (3+ teams)
Temporal: 0.40 (1 week deadline)
Technical: 0.80 (real-time WebSocket)
Scale: 0.50 (<100ms latency)
Uncertainty: 0.15 (clear requirements)
Dependencies: 0.30 (external APIs)

Weighted Total: 0.72 (HIGH)
```

**Interpretation Bands**:
```
0.00-0.30: Simple (1-2 agents, hours-1 day)
0.30-0.50: Moderate (2-3 agents, 1-2 days)
0.50-0.70: Complex (3-7 agents, 2-4 days)
0.70-0.85: High (8-15 agents, 1-2 weeks)
0.85-1.00: Critical (15-25 agents, 2+ weeks)
```

**Domain Detection** (keyword counting):
```python
# Count keywords per domain
frontend_count = count_keywords(["React", "Vue", "component", "UI", "CSS"])
backend_count = count_keywords(["API", "Express", "server", "microservice"])
database_count = count_keywords(["PostgreSQL", "schema", "SQL", "migration"])

# Calculate percentages
total = frontend_count + backend_count + database_count
frontend_percent = (frontend_count / total) Ã— 100
backend_percent = (backend_count / total) Ã— 100
database_percent = (database_count / total) Ã— 100

# Normalize to 100%
```

**MCP Recommendations** (tiered):
```
Tier 1 (MANDATORY): Serena (always)

Tier 2 (PRIMARY) if domain â‰¥20%:
  - Frontend â‰¥20% â†’ Magic MCP, Puppeteer MCP
  - Backend â‰¥20% â†’ Context7 MCP
  - Database â‰¥15% â†’ PostgreSQL/MongoDB MCP

Tier 3 (SECONDARY): GitHub MCP, AWS MCP

Tier 4 (OPTIONAL): Research MCPs if needed
```

**5-Phase Plan Generation**:
```
Phase 1: Analysis & Planning (15%)
Phase 2: Architecture & Design (20%)
Phase 3: Implementation (40%)
Phase 4: Integration & Testing (15%)
Phase 5: Deployment & Documentation (10%)
```

**Serena Save**:
```javascript
write_memory("spec_analysis_20250103_143022", {
  complexity_score: 0.68,
  domain_percentages: {Frontend: 34, Backend: 29, ...},
  mcp_recommendations: [...],
  phase_plan: [...]
})
```

---

### 3.5 task-automation Skill (Workflow Orchestration)

**Purpose**: Automate complete Shannon workflow (prime â†’ spec â†’ wave)

**Workflow**:
```
Step 1: Session Preparation
â†’ SlashCommand("/shannon:prime")
â†’ Discover 104+ skills, verify MCPs, restore context

Step 2: Validate Input
â†’ Check spec â‰¥20 words

Step 3: Specification Analysis
â†’ SlashCommand("/shannon:spec \"[spec]\" --save")
â†’ Capture: complexity, domains, strategy, waves

Step 4: User Decision (unless --auto)
â†’ Ask: Execute waves? (yes/plan/skip/abort)

Step 5: Wave Execution
â†’ SlashCommand("/shannon:wave")
â†’ Loop: Execute wave â†’ synthesis â†’ ask to continue

Step 6: Task Complete
â†’ Summary: phases executed, deliverables, next actions
```

**Modes**:
```bash
# Interactive (default)
/shannon:task "Build REST API"

# Fully automated
/shannon:task "Build login form" --auto

# Plan only (no execution)
/shannon:task "Build microservices" --plan-only
```

**Error Handling**:
```python
if error_in_wave:
    offer_options(["retry", "skip", "abort"])
    handle_user_choice()
```

**Anti-Rationalization**:
- Never skip prime (always run for consistency)
- Never skip spec (even for "simple" tasks)
- Always show spec results and ask (unless --auto)
- Handle errors gracefully with recovery options

---

## 4. Command Structure Analysis

### 4.1 Command Pattern (Universal)

**YAML Frontmatter**:
```yaml
---
name: command-name
description: Human-readable purpose
usage: /shannon:command [args]
category: core|workflow|analysis|tools
---
```

**Markdown Body**:
```markdown
# Command Title

## Purpose
What this command does

## Usage
/shannon:command [args]

## How It Works
@skill skill-name
  parameter: value
  parameter: value

## Examples
[Concrete usage examples]

## Related
- Other commands
- Skills used
```

### 4.2 Key Commands

**prime.md**:
```yaml
name: prime
usage: /shannon:prime
description: Session preparation and context restoration
```

**spec.md**:
```yaml
name: spec
usage: /shannon:spec "[specification]"
description: 8-dimensional complexity analysis
```

**wave.md**:
```yaml
name: wave
usage: /shannon:wave [--plan]
description: Execute parallel wave-based implementation
```

**task.md**:
```yaml
name: task
usage: /shannon:task "[spec]" [--auto|--plan-only]
description: Complete workflow automation (primeâ†’specâ†’wave)
```

**exec.md**:
```yaml
name: exec
usage: /shannon:exec "[task]"
description: Autonomous execution with validation and commits
```

**checkpoint.md**:
```yaml
name: checkpoint
usage: /shannon:checkpoint [key]
description: Create/restore Serena checkpoints
```

---

## 5. Serena MCP Integration Patterns

### 5.1 Where Serena is Used

**In Skills** (not Python):

1. **spec-analysis**: Save complete analysis
```javascript
write_memory("spec_analysis_20250103_143022", {
  complexity_score: 0.68,
  domain_percentages: {...},
  ...
})
```

2. **wave-orchestration**: Context loading + synthesis
```javascript
// Before wave
list_memories()
read_memory("spec_analysis")
read_memory("wave_1_complete")

// After wave
write_memory("wave_2_complete", {
  deliverables: {...},
  decisions: [...],
  next_wave_context: {...}
})
```

3. **exec**: Cache library discoveries + execution state
```javascript
// Cache libraries (7-day TTL)
write_memory("library_cache_authentication", {
  libraries: [...],
  cached_at: timestamp
})

// Save execution results
write_memory("exec_result_20250103_150000", {
  success: true,
  commits: [...],
  libraries_used: [...]
})
```

4. **context-preservation**: Checkpoint creation
```javascript
write_memory("checkpoint_pre_wave_3", {
  wave_state: {...},
  todo_state: {...},
  decisions: [...]
})

write_memory("shannon_latest_checkpoint", {
  checkpoint_key: "checkpoint_pre_wave_3",
  timestamp: "...",
  type: "manual"
})
```

### 5.2 Serena Entity Types (from skills)

**Memory Keys Used**:
```
spec_analysis_{timestamp}         # Complexity analysis
phase_plan_detailed                # 5-phase plan
architecture_complete              # System design
wave_{N}_complete                  # Wave synthesis
wave_{N}_{agent}_results          # Individual agent results
library_cache_{feature}            # Library discoveries
exec_result_{timestamp}            # Execution reports
checkpoint_{name}                  # Manual checkpoints
shannon_precompact_checkpoint_{ts} # Auto checkpoints
shannon_latest_checkpoint          # Pointer to latest
```

**No Entity/Relation System**: Shannon uses Serena as simple key-value store, not knowledge graph

---

## 6. Testing Infrastructure

### 6.1 Test Structure

**Directory Layout**:
```
tests/
â”œâ”€â”€ conftest.py                    # pytest config
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ test_decision_engine.py
â”‚   â”œâ”€â”€ test_halt_resume.py
â”‚   â”œâ”€â”€ run_halt_resume_tests.py
â”‚   â””â”€â”€ run_rollback_tests.py
â”œâ”€â”€ server/
â”‚   â””â”€â”€ test_websocket_decisions.py
â”œâ”€â”€ e2e/
â”‚   â””â”€â”€ test_decision_engine_e2e.py
â”œâ”€â”€ tier1_verify_analysis.py      # Verify spec-analysis
â”œâ”€â”€ tier2_build_*.py               # Build test projects
â”œâ”€â”€ validate_skills.py             # Validate all skills
â””â”€â”€ verification-skill/            # Functional test skill
```

### 6.2 Testing Philosophy (NO MOCKS)

**From post_tool_use.py hook**:
```python
# Blocked patterns
MOCK_PATTERNS = [
    'jest.mock()',
    'unittest.mock',
    '@patch',
    'mockImplementation',
    'mockReturnValue',
    'sinon.stub',
    'vi.mock()'
]
```

**Functional Testing Requirements**:
```
Frontend: Puppeteer (real browser, NO MOCKS)
Backend: Real HTTP requests (NO MOCKS)
Database: Real database instance (NO MOCKS)
Mobile: iOS Simulator or Android Emulator (NO MOCKS)
```

**Test Validation** (from functional-testing skill):
```bash
# Frontend
npm run dev  # Start real server
puppeteer.launch()  # Real browser
page.goto('http://localhost:3000')  # Real navigation
page.click('#login-button')  # Real interaction

# Backend
curl http://localhost:8000/api/users  # Real HTTP

# Database
psycopg2.connect(real_db_url)  # Real PostgreSQL
```

---

## 7. Dashboard & Real-Time Control

### 7.1 WebSocket Events

**Client â†’ Server**:
```
halt_execution          â†’ HALT waves
resume_execution        â†’ RESUME waves
rollback_execution      â†’ ROLLBACK N steps
approve_decision        â†’ Approve pending decision
get_execution_status    â†’ Get current status
request_pending_decisions â†’ Get pending list
```

**Server â†’ Client**:
```
execution:halted        â†’ HALT confirmed
execution:resumed       â†’ RESUME confirmed
execution:rolled_back   â†’ ROLLBACK confirmed
execution:status_update â†’ Status broadcast
decision:requested      â†’ New decision needs approval
decision:approved       â†’ Decision approved
decisions:pending       â†’ List of pending decisions
```

### 7.2 Decision Flow

```
Orchestrator: High-confidence decision (â‰¥0.95)
â†“
Decision Engine: Auto-approve
â†“
Continue execution (no human needed)

---

Orchestrator: Low-confidence decision (<0.95)
â†“
Decision Engine: Create pending decision
â†“
WebSocket: Emit decision:requested
â†“
Dashboard: Show to user
â†“
User: Select option
â†“
WebSocket: Receive approve_decision
â†“
Decision Engine: Mark approved
â†“
WebSocket: Emit execution:resumed
â†“
Orchestrator: Continue execution
```

---

## 8. Complete Project Structure

```
shannon-framework/
â”œâ”€â”€ .claude-plugin/
â”‚   â”œâ”€â”€ plugin.json          # Shannon plugin manifest
â”‚   â””â”€â”€ marketplace.json     # Marketplace listing
â”œâ”€â”€ commands/                # 16 slash commands
â”‚   â”œâ”€â”€ analyze.md
â”‚   â”œâ”€â”€ checkpoint.md
â”‚   â”œâ”€â”€ exec.md
â”‚   â”œâ”€â”€ prime.md
â”‚   â”œâ”€â”€ spec.md
â”‚   â”œâ”€â”€ task.md
â”‚   â”œâ”€â”€ wave.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ skills/                  # 19 skills
â”‚   â”œâ”€â”€ exec/
â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â”œâ”€â”€ wave-orchestration/
â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â”œâ”€â”€ spec-analysis/
â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â”œâ”€â”€ task-automation/
â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ hooks/                   # Python hooks
â”‚   â”œâ”€â”€ post_tool_use.py     # NO MOCKS enforcement
â”‚   â”œâ”€â”€ precompact.py        # Auto-checkpoint
â”‚   â”œâ”€â”€ stop.py              # Validation gates
â”‚   â””â”€â”€ user_prompt_submit.py # North Star injection
â”œâ”€â”€ orchestration/           # Python orchestration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py      # Wave coordination
â”‚   â”œâ”€â”€ state_manager.py     # Snapshot/rollback
â”‚   â””â”€â”€ decision_engine.py   # Human-in-loop
â”œâ”€â”€ server/                  # WebSocket server
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ websocket.py         # Real-time control
â”œâ”€â”€ tests/                   # Functional tests
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ e2e/
â”‚   â”œâ”€â”€ tier1_verify_analysis.py
â”‚   â”œâ”€â”€ tier2_build_*.py
â”‚   â””â”€â”€ validate_skills.py
â”œâ”€â”€ dashboard/               # React dashboard (not analyzed)
â”œâ”€â”€ validate_shannon_v5.py   # System validator
â”œâ”€â”€ run_tests.py             # Test runner
â””â”€â”€ README.md

Total Files Analyzed: 34 Python files + 19 skills + 16 commands = 69 files
```

---

## 9. Key Patterns for intelligent-do

### 9.1 Skill Invocation Pattern

**From task-automation.md**:
```markdown
SlashCommand("/shannon:prime")
SlashCommand("/shannon:spec \"[specification]\" --save")
SlashCommand("/shannon:wave")
```

**From exec.md**:
```markdown
@skill context-preservation
  operation: prepare
  task_focused: true

@skill wave-orchestration
  task: {step.description}
  enhanced_context: |
    RECOMMENDED LIBRARIES: {libraries}
    CRITICAL INSTRUCTIONS: ...
```

### 9.2 Serena Patterns

**Save Analysis**:
```javascript
write_memory("spec_analysis_20250103_143022", {
  complexity_score: 0.68,
  ...
})
```

**Context Loading**:
```javascript
list_memories()
read_memory("spec_analysis")
read_memory("wave_1_complete")
```

**Checkpoint**:
```javascript
write_memory("checkpoint_pre_wave_3", {...})
write_memory("shannon_latest_checkpoint", {
  checkpoint_key: "checkpoint_pre_wave_3"
})
```

### 9.3 TodoWrite Usage

**From skills** (not Python):
```javascript
// Create todo list
TodoWrite([
  {content: "Phase 1: Analysis", status: "in_progress", activeForm: "Analyzing..."},
  {content: "Phase 2: Design", status: "pending", activeForm: "Designing..."},
  {content: "Phase 3: Implementation", status: "pending", activeForm: "Implementing..."}
])

// Update status
TodoWrite([
  {content: "Phase 1: Analysis", status: "completed", activeForm: "Analyzed"},
  {content: "Phase 2: Design", status: "in_progress", activeForm: "Designing..."}
])
```

### 9.4 Validation Pattern

**3-Tier Validation** (exec skill):
```bash
# Tier 1: Static (10s)
shannon validate --tier 1 --json
# Returns: {tier1_passed: true, build: "PASS", typecheck: "PASS", lint: "PASS"}

# Tier 2: Tests (1-5min)
shannon validate --tier 2 --json
# Returns: {tier2_passed: true, tests_passed: 12, tests_failed: 0}

# Tier 3: Functional (2-10min)
shannon validate --tier 3 --json
# Returns: {tier3_passed: true, functional_test: "Feature works in browser"}
```

### 9.5 Git Automation Pattern

**From exec skill**:
```bash
# On validation success
shannon git-commit \
  --step "Add authentication" \
  --files "package.json,src/auth/login.tsx" \
  --validation-json '{"tier1_passed": true, "tier2_passed": true, "tier3_passed": true}'

# On validation failure
shannon git-rollback
```

---

## 10. Building intelligent-do: Required Components

Based on exhaustive analysis, intelligent-do needs:

### 10.1 SKILL.md Structure

```yaml
---
name: intelligent-do
description: |
  Intelligent task execution with context awareness and auto-exploration.
  Analyzes user intent, explores codebase, discovers libraries, validates
  functionally, commits atomically. Use when: user says "do X" without
  detailed specification.

skill-type: PROTOCOL
shannon-version: ">=5.1.0"

mcp-requirements:
  required:
    - name: serena
      purpose: Context storage, library cache
  recommended:
    - name: sequential
      purpose: Intent analysis, exploration planning

required-sub-skills:
  - exec
  - spec-analysis

optional-sub-skills:
  - wave-orchestration

allowed-tools: [Bash, Read, Write, Grep, Glob, Serena, Sequential, TodoWrite]
---
```

### 10.2 Core Workflow

```
Phase 1: Intent Analysis (1-2 min)
â†’ Parse user's "do X" command
â†’ Determine if spec needed or context exists
â†’ If ambiguous: Ask clarifying questions

Phase 2: Context Discovery (2-5 min)
â†’ Explore codebase with Glob/Grep
â†’ Search Serena for previous decisions
â†’ Build context map

Phase 3: Specification Synthesis (30s-2min)
â†’ IF user provided full spec: Use directly
â†’ ELSE: Generate spec from intent + context
â†’ Run /shannon:spec on synthesized spec

Phase 4: Execution (Delegate to exec)
â†’ @skill exec
    task: {synthesized_spec_with_context}
â†’ exec handles: library discovery, wave execution, validation, commits

Phase 5: Verification (1-2 min)
â†’ Review exec output
â†’ Confirm intent satisfied
â†’ Report to user
```

### 10.3 Serena Integration

```javascript
// Check for existing context
read_memory("intelligent_do_last_context")

// Cache discoveries
write_memory("intelligent_do_codebase_map", {
  file_structure: {...},
  key_patterns: {...},
  dependencies: {...}
})

// Save synthesized spec
write_memory("intelligent_do_synthesized_spec", {
  original_intent: "...",
  synthesized_spec: "...",
  context_used: [...]
})
```

### 10.4 Integration Points

- **Uses spec-analysis**: For complexity scoring synthesized spec
- **Uses exec**: For actual execution with validation
- **Uses wave-orchestration**: Via exec for complex tasks
- **Uses Serena**: For context caching and decisions
- **Uses TodoWrite**: For progress tracking across phases

---

## 11. Critical Findings

### 11.1 Python Code Does NOT Use Serena

**Confirmed**: Python orchestration provides infrastructure, Skills invoke Serena MCP

### 11.2 NO MOCKS Philosophy Enforced in Real-Time

**Hook**: post_tool_use.py blocks any test file writes containing mock patterns

### 11.3 Wave Orchestration Requires Specific Pattern

**MUST**: Spawn all agents in ONE message for true parallelism
**MUST**: Include context loading protocol in every agent
**MUST**: Create synthesis checkpoint after EVERY wave

### 11.4 Three-Tier Validation is Non-Negotiable

**Tier 1**: Build + TypeCheck + Lint
**Tier 2**: All tests passing (functional, NO MOCKS)
**Tier 3**: Real system behavior validated

### 11.5 Serena is Key-Value Store, Not Knowledge Graph

**Pattern**: write_memory(key, json), read_memory(key)
**No**: create_entities, create_relations, add_observations

---

## 12. Next Steps for intelligent-do

1. **Create SKILL.md** with complete workflow
2. **Define intent parsing** algorithm (Sequential MCP)
3. **Build context discovery** using Glob/Grep/Read
4. **Implement spec synthesis** logic
5. **Delegate to exec** with enriched context
6. **Create /shannon:do command** invoking intelligent-do skill
7. **Test with examples**: "do authentication", "do dashboard", "do API"

---

**End of Complete Analysis**

Total Lines Analyzed: 5,000+ Python lines, 10,000+ skill lines
Analysis Depth: Line-by-line exhaustive
Purpose Achieved: Complete understanding for building intelligent-do
